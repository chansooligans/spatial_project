moran_I_2 = morans_I(wm=wm2, df$z)
moran_I_3 = morans_I(wm=wm3, df$z)
moran_mc = function(n, weight_matrix, z, random){
morans_I_sims = rep(NA,n)
if(random==TRUE){
for(i in 1:n){
z_ = sample(z)
morans_I_sims[i] = morans_I(wm=weight_matrix, z_)
}
}
else if(random==FALSE) {
for(i in 1:n){
z_ = rnorm(121)
morans_I_sims[i] = morans_I(wm=weight_matrix, z_)
}
}
return(morans_I_sims)
}
moran_I_1
mc_sim_1 = moran_mc(n=1000, wm1, df$z, random=FALSE)
mc_sim_2 = moran_mc(n=1000, wm2, df$z, random=FALSE)
mc_sim_3 = moran_mc(n=1000, wm3, df$z, random=FALSE)
# Density Plots
hist(mc_sim_1, xlim=c(-0.3,0.8))
abline(v=moran_I_1, col = 2)
hist(mc_sim_2, xlim=c(-0.3,0.8))
abline(v=moran_I_2, col = 2)
hist(mc_sim_3, xlim=c(-0.3,0.8))
abline(v=moran_I_3, col = 2)
# P-values
p_val1 = 2*(1-pnorm(moran_I_1,
mean=mean(mc_sim_1),
sd=sd(mc_sim_1)))
p_val2 = 2*(1-pnorm(moran_I_2,
mean=mean(mc_sim_2),
sd=sd(mc_sim_2)))
p_val3 = 2*(1-pnorm(moran_I_3,
mean=mean(mc_sim_3),
sd=sd(mc_sim_3)))
p_val1
p_val2
p_val3
exp.variogram.mod = function(h, sigma=1, rho=0.05){
return((sigma^2)*(1-exp(-3*h/rho)))
}
S_ = seq(0,1,0.1)
coords = expand.grid(S_,S_)
distmat = as.matrix(dist(coords))
covmat = 1-exp.variogram.mod(distmat)
z = mvrnorm(n = 1,
mu = rep(0,length(S_)^2),
Sigma = covmat)
df2 = cbind(coords,z)
vgm1 <- variogram(z ~ 1, loc=~Var1+Var2, data = df2)
plot(vgm1)
moran_I_1rho05 = morans_I(wm=wm1, df2$z)
moran_I_2rho05 = morans_I(wm=wm2, df2$z)
moran_I_3rho05 = morans_I(wm=wm3, df2$z)
p_val1_b = 2*(1-pnorm(moran_I_1rho05, mean=mean(mc_sim_1), sd=sd(mc_sim_1)))
p_val2_b = 2*(1-pnorm(moran_I_2rho05, mean=mean(mc_sim_2), sd=sd(mc_sim_2)))
p_val3_b = 2*(1-pnorm(moran_I_3rho05, mean=mean(mc_sim_3), sd=sd(mc_sim_3)))
p_val1_b
p_val2_b
p_val3_b
pnorm(moran_I_1rho05, mean=mean(mc_sim_1), sd=sd(mc_sim_1))
pnorm(moran_I_2rho05, mean=mean(mc_sim_2), sd=sd(mc_sim_2))
pnorm(moran_I_3rho05, mean=mean(mc_sim_3), sd=sd(mc_sim_3))
pnorm(moran_I_2rho05, mean=mean(mc_sim_2), sd=sd(mc_sim_2))
?pnorm()
pnorm(moran_I_2rho05, mean=mean(mc_sim_2), sd=sd(mc_sim_2))
pnorm(moran_I_3rho05, mean=mean(mc_sim_3), sd=sd(mc_sim_3))
p_val3_b = 2*(pnorm(moran_I_3rho05, mean=mean(mc_sim_3), sd=sd(mc_sim_3)))
p_val3_b
z = rnorm(121)
df3 = cbind(coords,z)
vgm1 <- variogram(z ~ 1, loc=~Var1+Var2, data = df3)
plot(vgm1)
moran_I_1_iid = morans_I(wm=wm1, df3$z)
moran_I_2_iid = morans_I(wm=wm2, df3$z)
moran_I_3_iid = morans_I(wm=wm3, df3$z)
p_val1_c = 2*(pnorm(moran_I_1_iid, mean=mean(mc_sim_1), sd=sd(mc_sim_1)))
p_val2_c = 2*(1-pnorm(moran_I_2_iid, mean=mean(mc_sim_2), sd=sd(mc_sim_2)))
p_val3_c = 2*(pnorm(moran_I_3_iid, mean=mean(mc_sim_3), sd=sd(mc_sim_3)))
p_val1_c
pnorm(moran_I_1_iid, mean=mean(mc_sim_1), sd=sd(mc_sim_1))
p_val2_c = 2*(1-pnorm(moran_I_2_iid, mean=mean(mc_sim_2), sd=sd(mc_sim_2)))
p_val2_c
p_val3_c = 2*(pnorm(moran_I_3_iid, mean=mean(mc_sim_3), sd=sd(mc_sim_3)))
p_val3_c
p_val3_c = 2*(1-pnorm(moran_I_3_iid, mean=mean(mc_sim_3), sd=sd(mc_sim_3)))
p_val3_c
rho1 = c(p_val1,p_val2,p_val3)
rho05 = c(p_val1_b,p_val2_b,p_val3_b)
iid = c(p_val1_c,p_val2_c,p_val3_c)
compare_results = data.frame(rho1, rho05, iid)
colnames(compare_results) = c("rho = 1", "rho = 0.05", "IID")
row.names(compare_results) = c("1NN","2NN","3NN")
# P-values for data generated using rho = 1, rho = 0.05, IID
# MC Simulation with null hypothesis relying on normality assumption
compare_results
p_val1_c
pnorm(moran_I_1_iid, mean=mean(mc_sim_1), sd=sd(mc_sim_1))
p_val1_c = 2*(pnorm(moran_I_1_iid, mean=mean(mc_sim_1), sd=sd(mc_sim_1)))
p_val2_c = 2*(1-pnorm(moran_I_2_iid, mean=mean(mc_sim_2), sd=sd(mc_sim_2)))
p_val3_c = 2*(1-pnorm(moran_I_3_iid, mean=mean(mc_sim_3), sd=sd(mc_sim_3)))
rho1 = c(p_val1,p_val2,p_val3)
rho05 = c(p_val1_b,p_val2_b,p_val3_b)
iid = c(p_val1_c,p_val2_c,p_val3_c)
compare_results = data.frame(rho1, rho05, iid)
colnames(compare_results) = c("rho = 1", "rho = 0.05", "IID")
row.names(compare_results) = c("1NN","2NN","3NN")
# P-values for data generated using rho = 1, rho = 0.05, IID
# MC Simulation with null hypothesis relying on normality assumption
compare_results
pnorm(moran_I_1_iid, mean=mean(mc_sim_1), sd=sd(mc_sim_1))
p_val1_c = 2*(1-pnorm(moran_I_1_iid, mean=mean(mc_sim_1), sd=sd(mc_sim_1)))
p_val1_c
p_val1_c = 2*(1-pnorm(moran_I_1_iid, mean=mean(mc_sim_1), sd=sd(mc_sim_1)))
p_val2_c = 2*(1-pnorm(moran_I_2_iid, mean=mean(mc_sim_2), sd=sd(mc_sim_2)))
p_val3_c = 2*(1-pnorm(moran_I_3_iid, mean=mean(mc_sim_3), sd=sd(mc_sim_3)))
rho1 = c(p_val1,p_val2,p_val3)
rho05 = c(p_val1_b,p_val2_b,p_val3_b)
iid = c(p_val1_c,p_val2_c,p_val3_c)
compare_results = data.frame(rho1, rho05, iid)
colnames(compare_results) = c("rho = 1", "rho = 0.05", "IID")
row.names(compare_results) = c("1NN","2NN","3NN")
# P-values for data generated using rho = 1, rho = 0.05, IID
# MC Simulation with null hypothesis relying on normality assumption
compare_results
N = nrow(df)
exp_Moran_I = -1/(N - 1)
compute_var_I = function(wm){
w_ip = apply(wm,1,sum)
w_pj = apply(wm,2,sum)
s_0 = sum(wm1)
s_1 = 0.5*sum( apply((wm + t(wm)),1,sum)^2 )
s_2 = sum((w_ip + w_pj)^2)
var_I = (((N^2)*s_1 - N*s_2 + 3*s_0^3) / ((N-1)*(N+1)*s_0^2)) - exp_Moran_I^2
return(var_I)
}
var_MoranI_1 = compute_var_I(wm1)
var_MoranI_2 = compute_var_I(wm2)
var_MoranI_3 = compute_var_I(wm3)
z_score_1 = (moran_I_1 - exp_Moran_I) / sqrt(var_MoranI_1)
z_score_2 = (moran_I_2 - exp_Moran_I) / sqrt(var_MoranI_2)
z_score_3 = (moran_I_3 - exp_Moran_I) / sqrt(var_MoranI_3)
test_pval = 2*(1-pnorm(z_score_1))
test_pval2 = 2*(1-pnorm(z_score_2))
test_pval3 = 2*(1-pnorm(z_score_3))
rho1_hp = c(test_pval,test_pval2,test_pval3)
rho1 = c(p_val1,p_val2,p_val3)
compare_hp_mc = data.frame(rho1_hp, rho1)
colnames(compare_hp_mc) = c('asymptotics', 'MC sim')
row.names(compare_hp_mc) = c('1NN', '2NN', '3NN')
compare_hp_mc
p_val1_b
p_val2_b
p_val3_b
# P-values for data generated using rho = 1, rho = 0.05, IID
# MC Simulation with null hypothesis relying on normality assumption
compare_results
rm(list=ls())
library(ggplot2)
library(ggplot2)
library(gstat)
library(ggplot2)
library(gstat)
library(lattice)
library(maps)
library(spatstat)
library(spatstat)
library(maptools)
library(RColorBrewer)
library(classInt)
library(rgdal)
library(formatR)
library(sm)
library(sm)
library(smacpod)
library(rgdal)
library(formatR)
library(sm)
library(smacpod)
library(SpatialEpi)
library(spatstat)
library(maptools)
library(RColorBrewer)
library(classInt)
library(rgdal)
library(formatR)
library(sm)
library(smacpod)
library(SpatialEpi)
library(GISTools)
library(spatstat)
library(maptools)
library(RColorBrewer)
library(classInt)
library(rgdal)
library(formatR)
library(sm)
library(smacpod)
library(SpatialEpi)
library(GISTools)
library(dplyr)
load('Data/Stop_Frisk/stops2013clean.RData')
# Subset data
df = stops2013clean[samples,cols_to_keep]
# Subset data
df = stops2013clean[,cols_to_keep]
cols_to_keep = c("id","lon","lat","year","precinct","found.contraband","found.pistol","found.rifle","found.assault","found.knife","found.machinegun","found.other","found.gun","found.weapon")
cols_to_keep = c("id",
"lon",
"lat",
"year",
"precinct",
"found.contraband",
"found.pistol",
"found.rifle",
"found.assault",
"found.knife",
"found.machinegun",
"found.other",
"found.gun",
"found.weapon")
# Subset data
df = stops2013clean[,cols_to_keep]
rm(stops2013clean)
nyc <- readOGR("Borough_Boundaries/geo_export_5e515234-1937-40b5-b942-1ef10ea3ea45.shp" )
nyc <- readOGR("Data/Borough_Boundaries/geo_export_5e515234-1937-40b5-b942-1ef10ea3ea45.shp" )
plot(nyc)
with(df, points(lon, lat, pch = "."))
plot(nyc)
with(df, points(lon, lat, pch = "."))
colnames(df)
cols_hit = c("found.contraband",
"found.pistol",
"found.rifle",
"found.assault",
"found.knife",
"found.machinegun",
"found.other",
"found.gun",
"found.weapon")
df[,cols_hit]
apply(df[,cols_hit],2,sum)
apply(df[,cols_hit],1,sum)
df$hit = ifelse(apply(df[,cols_hit],1,sum)>0,1,0)
df$hit
mean(df$hit)
plot(nyc)
with(df, points(lon, lat, pch = ".", col = df$hit))
plot(nyc)
with(df, points(lon, lat, pch = ".", col = df$hit+1))
make_circles <- function(centers, radius, nPoints = 100){
# centers: the data frame of centers with ID
# radius: radius measured in kilometer
#
meanLat <- mean(centers$latitude)
# length per longitude changes with lattitude, so need correction
radiusLon <- radius /111 / cos(meanLat/57.3)
radiusLat <- radius / 111
circleDF <- data.frame(ID = rep(centers$ID, each = nPoints))
angle <- seq(0,2*pi,length.out = nPoints)
circleDF$lon <- unlist(lapply(centers$longitude, function(x) x + radiusLon * cos(angle)))
circleDF$lat <- unlist(lapply(centers$latitude, function(x) x + radiusLat * sin(angle)))
return(circleDF)
}
data = read.csv('/Users/Chansoo/Desktop/Spatial_Project/results/Manhattan_0.01_result.csv',header = F)
data
data = read.csv('/Users/Chansoo/Desktop/Spatial_Project/results/Manhattan_0.01_result.csv',header = T)
data
data = read.csv('/Users/Chansoo/Desktop/Spatial_Project/results/Manhattan_0.01_result.csv',header = T, nrow=4)
data
make_circles <- function(centers, radius, nPoints = 100){
# centers: the data frame of centers with ID
# radius: radius measured in kilometer
#
meanLat <- mean(centers$lat)
# length per longitude changes with lattitude, so need correction
radiusLon <- radius /111 / cos(meanLat/57.3)
radiusLat <- radius / 111
circleDF <- data.frame(ID = rep(centers$X, each = nPoints))
angle <- seq(0,2*pi,length.out = nPoints)
circleDF$lon <- unlist(lapply(centers$lon, function(x) x + radiusLon * cos(angle)))
circleDF$lat <- unlist(lapply(centers$lat, function(x) x + radiusLat * sin(angle)))
return(circleDF)
}
data = read.csv('/Users/Chansoo/Desktop/Spatial_Project/results/Manhattan_0.01_result.csv',header = T, nrow=4)
# here is the data frame for all circles
myCircles <- make_circles(data, 0.45)
myCircles
library(ggplot2)
library(ggmap)
?get_map()
island = get_map(location = c(lon = 74.0060, lat = 40.7128), zoom = 13, maptype = "satellite")
nyc_map = get_map(location = c(lon = -74.0060, lat = 40.7128), zoom = 13, maptype = "satellite")
nyc_map = get_map(location = c(lon = -73.935242, lat = 40.7128), zoom = 13, maptype = "satellite")
nyc_map = get_map(location = c(lon = -73.935242, lat = 40.7128),
zoom = 13,
maptype = "satellite",
api_key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
nyc_map = get_map(location = c(lon = -73.935242, lat = 40.7128),
zoom = 13,
maptype = "satellite",
api_key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
nyc_map = get_map(location = c(lon = -73.935242, lat = 40.7128),
zoom = 13,
maptype = "roadmap",
source = "google"
,                  api_key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
nyc_map = get_googlemap(location = c(lon = -73.935242, lat = 40.7128),
zoom = 13,
maptype = "roadmap",
source = "google"
,                 api_key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
register_google(key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
?register_google()
library(ggmap)
register_google(key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
install.packages('ggmap')
install.packages("ggmap")
register_google(key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
devtools::install_github("ggmap")
devtools::install_github("r/ggmap")
devtools::install_github("dkahle/ggmap")
register_google(key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
devtools::install_github("dkahle/ggmap", ref = "tidyup")
# devtools::install_github("dkahle/ggmap", ref = "tidyup")
?register_google()
ggmap::register_google(key = "AIzaSyC4ABT6F3JznHUr-uCTAFs4R3lgDYNul_k")
library(ggmap)
library(shiny); runApp('Desktop/Spatial_Project/Spatial_Shiny_App2/app_population.R')
runApp('Desktop/Spatial_Project/Spatial_Shiny_App2/app_population.R')
runApp('Desktop/Spatial_Project/Spatial_Shiny_App3/app_doughnut.R')
runApp('Desktop/Spatial_Project/Spatial_Shiny_App/app_radius.R')
radius = 0.01
load('Data/app_radius_candidates.RData')
# boroughs = c("Bronx", "Brooklyn", "Manhattan", "Queens", "Staten Island")
# result_files = paste('results/',boroughs,'_',radius,'_result.csv',sep='')
#
# candidate_centers = as.data.frame(matrix(0,nrow=5,ncol=4))
# colnames(candidate_centers) = c('X','lon','lat','n')
#
#
# for (i in 1:length(result_files)) {
#   result_file = read.csv(result_files[i], header=T)
#   candidate = result_file[1,c('X','lon','lat')]
#   # Distances between Center and All Stops
#   dists = sqrt((df$lon - candidate$lon)^ 2 + (df$lat - candidate$lat)^ 2)
#   # Count Stops in Circle
#   n = sum(ifelse(dists < radius, 1, 0))
#
#   candidate_centers[i,] = c(candidate, n)
# }
# save(candidate_centers, file='Data/app_radius_candidates.RData')
# Winner
center = candidate_centers %>%
arrange(-n) %>%
dplyr::select(X,lon,lat) %>%
head(1)
# Distances between Center and All Stops
dists = sqrt((df$lon - center$lon)^ 2 + (df$lat - center$lat)^ 2)
# Hit Rate of Stops within Radius
in_circle = ifelse(dists < radius, 1, 0)
center_hit_rate = sum(in_circle * df$hit) / sum(in_circle)
load('Data/stops2013clean.RData')
stops2013clean = as.data.frame(stops2013clean)
# CSV containing precincts and corresponding borough
prec_bor = read.csv('Data/prec_to_boroughs.csv', header = F, stringsAsFactors = F)
# Column names of prec_bor
colnames(prec_bor) = c('precinct','borough')
# Subset stop and frisk data
cols_to_keep = c("id",
"lon",
"lat",
"year",
"precinct",
"found.contraband",
"found.pistol",
"found.rifle",
"found.assault",
"found.knife",
"found.machinegun",
"found.other",
"found.gun",
"found.weapon")
df = stops2013clean[,cols_to_keep]
# Create "Hits" column in Stop and Frisk Data
cols_hit = c("found.contraband",
"found.pistol",
"found.rifle",
"found.assault",
"found.knife",
"found.machinegun",
"found.other",
"found.gun",
"found.weapon")
# hits column
df$hit = ifelse( apply(df[,cols_hit],1,sum)>0, 1, 0)
# Merge Stop and Frisk Data and Precinct_Borough Data
df$precinct = as.integer(as.character(df$precinct))
df = df %>%
left_join(prec_bor, by = 'precinct')
##### High Concentration Circle #####
# Radius
radius = 0.01
load('Data/app_radius_candidates.RData')
# boroughs = c("Bronx", "Brooklyn", "Manhattan", "Queens", "Staten Island")
# result_files = paste('results/',boroughs,'_',radius,'_result.csv',sep='')
#
# candidate_centers = as.data.frame(matrix(0,nrow=5,ncol=4))
# colnames(candidate_centers) = c('X','lon','lat','n')
#
#
# for (i in 1:length(result_files)) {
#   result_file = read.csv(result_files[i], header=T)
#   candidate = result_file[1,c('X','lon','lat')]
#   # Distances between Center and All Stops
#   dists = sqrt((df$lon - candidate$lon)^ 2 + (df$lat - candidate$lat)^ 2)
#   # Count Stops in Circle
#   n = sum(ifelse(dists < radius, 1, 0))
#
#   candidate_centers[i,] = c(candidate, n)
# }
# save(candidate_centers, file='Data/app_radius_candidates.RData')
# Winner
center = candidate_centers %>%
arrange(-n) %>%
dplyr::select(X,lon,lat) %>%
head(1)
# Distances between Center and All Stops
dists = sqrt((df$lon - center$lon)^ 2 + (df$lat - center$lat)^ 2)
# Hit Rate of Stops within Radius
in_circle = ifelse(dists < radius, 1, 0)
center_hit_rate = sum(in_circle * df$hit) / sum(in_circle)
# Stop and Frisk Data
load('Data/stops2013clean.RData')
stops2013clean = as.data.frame(stops2013clean)
# CSV containing precincts and corresponding borough
prec_bor = read.csv('Data/prec_to_boroughs.csv', header = F, stringsAsFactors = F)
# Column names of prec_bor
colnames(prec_bor) = c('precinct','borough')
setwd('/Users/Chansoo/Desktop/Spatial_Project/')
# Stop and Frisk Data
load('Data/stops2013clean.RData')
stops2013clean = as.data.frame(stops2013clean)
# CSV containing precincts and corresponding borough
prec_bor = read.csv('Data/prec_to_boroughs.csv', header = F, stringsAsFactors = F)
# Column names of prec_bor
colnames(prec_bor) = c('precinct','borough')
# Subset stop and frisk data
cols_to_keep = c("id",
"lon",
"lat",
"year",
"precinct",
"found.contraband",
"found.pistol",
"found.rifle",
"found.assault",
"found.knife",
"found.machinegun",
"found.other",
"found.gun",
"found.weapon")
df = stops2013clean[,cols_to_keep]
# Create "Hits" column in Stop and Frisk Data
cols_hit = c("found.contraband",
"found.pistol",
"found.rifle",
"found.assault",
"found.knife",
"found.machinegun",
"found.other",
"found.gun",
"found.weapon")
# hits column
df$hit = ifelse( apply(df[,cols_hit],1,sum)>0, 1, 0)
# Merge Stop and Frisk Data and Precinct_Borough Data
df$precinct = as.integer(as.character(df$precinct))
df = df %>%
left_join(prec_bor, by = 'precinct')
# Radius
radius = 0.01
load('Data/app_radius_candidates.RData')
# Winner
center = candidate_centers %>%
arrange(-n) %>%
dplyr::select(X,lon,lat) %>%
head(1)
# Distances between Center and All Stops
dists = sqrt((df$lon - center$lon)^ 2 + (df$lat - center$lat)^ 2)
# Hit Rate of Stops within Radius
in_circle = ifelse(dists < radius, 1, 0)
center_hit_rate = sum(in_circle * df$hit) / sum(in_circle)
sum(in_circle)
runApp('Spatial_Shiny_App/app_radius.R')
runApp('Spatial_Shiny_App2/app_population.R')
runApp('Spatial_Shiny_App/app_radius.R')
runApp('Spatial_Shiny_App2/app_population.R')
runApp('Spatial_Shiny_App2/app_population.R')
runApp('Spatial_Shiny_App/app_radius.R')
runApp('Spatial_Shiny_App2/app_population.R')
runApp('Spatial_Shiny_App3/app_doughnut.R')
runApp('Spatial_Shiny_App/app_radius.R')
runApp('Spatial_Shiny_App2/app_population.R')
runApp('Spatial_Shiny_App3/app_doughnut.R')
runApp('Spatial_Shiny_App/app_radius.R')
runApp('Spatial_Shiny_App2/app_population.R')
runApp('Spatial_Shiny_App3/app_doughnut.R')
runApp('Spatial_Shiny_App/app_radius.R')
